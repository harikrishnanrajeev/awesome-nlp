{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fastai-ner-conll2003.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wcH0boFs3E_D",
        "ervox-PKKMuz",
        "UoyGJ13eoWyu",
        "yRkNpqL3C13E",
        "FkikvUNvowTs"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harirajeev/awesome-nlp/blob/master/fastai_ner_conll2003_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlPrMhKVSzDp",
        "colab_type": "text"
      },
      "source": [
        "Sources:\n",
        "\n",
        "https://github.com/piegu/language-models/blob/master/lm3-portuguese-classifier-TCU-jurisprudencia.ipynb\n",
        "\n",
        "https://colab.research.google.com/gist/davidpfahler/360606c7e6e66d78d82f7cb0e568f426/conll-fastai-v1.ipynb#scrollTo=Esp9SY33wwih\n",
        "\n",
        "https://gist.github.com/mamamot/822944e245622e904e9bccb32633cd97"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elmZXJ83x_2m",
        "colab_type": "code",
        "outputId": "54efbeb1-2118-4d7f-ff71-c48aaee3cd29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# !pip install fastai -q\n",
        "# !curl -s https://course.fast.ai/setup/colab | bash\n",
        "!pip install -U tqdm -q"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████▊                          | 10kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 30kB 3.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.1MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H4OhU3m4aRJ",
        "colab_type": "code",
        "outputId": "cd89dbf2-ef29-4c05-8ae4-43465f25495d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NesGI7uywmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "from functools import partial\n",
        "from pathlib import Path\n",
        "import json\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "root_dir = Path(\"/content/gdrive/My Drive/\")\n",
        "path = root_dir/\"fastai/NER/\"\n",
        "path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "# pd.set_option('display.max_columns', None)\n",
        "# pd.set_option('display.min_rows', 100)\n",
        "# pd.set_option('display.max_rows', 100)\n",
        "\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPGq5Sfgdv8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BS=128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg_BtC-44Ptf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_path = Path(path/\"conll2003\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRkhEmIm37g5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !git clone https://github.com/patverga/torch-ner-nlp-from-scratch.git\n",
        "# !mv torch-ner-nlp-from-scratch/data/conll2003 \"{dataset_path}\"/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNLR8w2q37Dh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !rm -rf torch-ner-nlp-from-scratch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcH0boFs3E_D",
        "colab_type": "text"
      },
      "source": [
        "# Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKUxNWN12vf_",
        "colab_type": "code",
        "outputId": "e2fb806e-e317-4689-a100-6a4462286760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df_train = pd.read_csv(dataset_path/\"eng.train\", sep=' ', header=None, usecols=[0,3], names=[\"Token\", \"Tag\"])\n",
        "df_train['valid'] = False\n",
        "df_train.dropna(subset=[\"Token\", \"Tag\"], inplace = True)\n",
        "df_train.reset_index(drop=True, inplace=True)\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Token</th>\n",
              "      <th>Tag</th>\n",
              "      <th>valid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-DOCSTART-</td>\n",
              "      <td>O</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>EU</td>\n",
              "      <td>I-ORG</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rejects</td>\n",
              "      <td>O</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>German</td>\n",
              "      <td>I-MISC</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>call</td>\n",
              "      <td>O</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Token     Tag  valid\n",
              "0  -DOCSTART-       O  False\n",
              "1          EU   I-ORG  False\n",
              "2     rejects       O  False\n",
              "3      German  I-MISC  False\n",
              "4        call       O  False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p2pGY2T1kPu",
        "colab_type": "code",
        "outputId": "e2ded415-e8ff-4cff-c21c-513d68943798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df_valid = pd.read_csv(dataset_path/\"eng.testa\", sep=' ', header=None, usecols=[0,3], names=[\"Token\", \"Tag\"])\n",
        "df_valid['valid'] = True\n",
        "df_valid.dropna(subset=[\"Token\", \"Tag\"], inplace = True)\n",
        "df_valid.reset_index(drop=True, inplace=True)\n",
        "df_test = pd.read_csv(dataset_path/\"eng.testb\", sep=' ', header=None, usecols=[0,3], names=[\"Token\", \"Tag\"])\n",
        "df_test.dropna(subset=[\"Token\", \"Tag\"], inplace = True)\n",
        "df_test.reset_index(drop=True, inplace=True)\n",
        "df_valid.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Token</th>\n",
              "      <th>Tag</th>\n",
              "      <th>valid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-DOCSTART-</td>\n",
              "      <td>O</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CRICKET</td>\n",
              "      <td>O</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-</td>\n",
              "      <td>O</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LEICESTERSHIRE</td>\n",
              "      <td>I-ORG</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TAKE</td>\n",
              "      <td>O</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Token    Tag  valid\n",
              "0      -DOCSTART-      O   True\n",
              "1         CRICKET      O   True\n",
              "2               -      O   True\n",
              "3  LEICESTERSHIRE  I-ORG   True\n",
              "4            TAKE      O   True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMvUOoN97mDe",
        "colab_type": "code",
        "outputId": "416e646e-40a0-417c-ec79-97792c754942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Token</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-DOCSTART-</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SOCCER</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>JAPAN</td>\n",
              "      <td>I-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GET</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Token    Tag\n",
              "0  -DOCSTART-      O\n",
              "1      SOCCER      O\n",
              "2           -      O\n",
              "3       JAPAN  I-LOC\n",
              "4         GET      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOmcYSS-VqyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_train.drop(df_train[df_train.Tag.isin([\"B-LOC\", \"B-ORG\", \"B-MISC\"])].index, inplace=True)\n",
        "# df_valid.drop(df_valid[df_valid.Tag.isin([\"B-LOC\", \"B-ORG\", \"B-MISC\"])].index, inplace=True)\n",
        "# df_test.drop(df_test[df_test.Tag.isin([\"B-LOC\", \"B-ORG\", \"B-MISC\"])].index, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev9diL046nKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train[\"Token\"] = df_train[\"Token\"].str.replace(\"-DOCSTART-\", \"xxbos\")\n",
        "df_valid[\"Token\"] = df_valid[\"Token\"].str.replace(\"-DOCSTART-\", \"xxbos\")\n",
        "df_test[\"Token\"] = df_test[\"Token\"].str.replace(\"-DOCSTART-\", \"xxbos\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ervox-PKKMuz",
        "colab_type": "text"
      },
      "source": [
        "# Preprocess "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y1gi5py7ufO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_to_docs(tokens, labels):\n",
        "  x, y, doc, lbs = [], [], [], []\n",
        "  for i, token in enumerate(tokens):\n",
        "    if token == 'xxbos' and len(doc) > 0:\n",
        "      x.append(doc)\n",
        "      y.append(lbs)\n",
        "      doc, lbs = [], []\n",
        "    doc.append(token)\n",
        "    lbs.append(labels[i])\n",
        "  x.append(doc)\n",
        "  y.append(lbs)\n",
        "  return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y46qsPZH75m5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x, train_y = split_to_docs(df_train['Token'], df_train['Tag'])\n",
        "valid_x, valid_y = split_to_docs(df_valid['Token'], df_valid['Tag'])\n",
        "test_x, test_y = split_to_docs(df_test['Token'], df_test['Tag'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iff_Qqoo79_2",
        "colab_type": "code",
        "outputId": "1a242e98-2a0e-4f78-dfa6-3c336dc4ef62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "train_df = pd.DataFrame({'tokens': train_x, 'labels': train_y})\n",
        "train_df['set'] = 'train'\n",
        "valid_df = pd.DataFrame(data = {'tokens': valid_x, 'labels': valid_y})\n",
        "valid_df['set'] = 'valid'\n",
        "test_df = pd.DataFrame(data = {'tokens': test_x, 'labels': test_y})\n",
        "test_df['set'] = 'test'\n",
        "df = pd.concat([train_df, valid_df], ignore_index=True)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>labels</th>\n",
              "      <th>set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[xxbos, EU, rejects, German, call, to, boycott, British, lamb, ., Peter, Blackburn, BRUSSELS, 1996-08-22, The, European, Commission, said, on, Thursday, it, disagreed, with, German, advice, to, co...</td>\n",
              "      <td>[O, I-ORG, O, I-MISC, O, O, O, I-MISC, O, O, I-PER, I-PER, I-LOC, O, O, I-ORG, I-ORG, O, O, O, O, O, O, I-MISC, O, O, O, O, O, I-MISC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, I-LOC, O, O, O, O, ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[xxbos, Rare, Hendrix, song, draft, sells, for, almost, $, 17,000, ., LONDON, 1996-08-22, A, rare, early, handwritten, draft, of, a, song, by, U.S., guitar, legend, Jimi, Hendrix, was, sold, for, ...</td>\n",
              "      <td>[O, O, I-PER, O, O, O, O, O, O, O, O, I-LOC, O, O, O, O, O, O, O, O, O, O, I-LOC, O, O, I-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, I-LOC, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[xxbos, China, says, Taiwan, spoils, atmosphere, for, talks, ., BEIJING, 1996-08-22, China, on, Thursday, accused, Taipei, of, spoiling, the, atmosphere, for, a, resumption, of, talks, across, the...</td>\n",
              "      <td>[O, I-LOC, O, I-LOC, O, O, O, O, O, I-LOC, O, I-LOC, O, O, O, I-LOC, O, O, O, O, O, O, O, O, O, O, O, I-LOC, I-LOC, O, O, O, O, I-LOC, O, I-MISC, O, O, I-PER, I-PER, O, O, O, O, I-LOC, O, O, O, O,...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[xxbos, China, says, time, right, for, Taiwan, talks, ., BEIJING, 1996-08-22, China, has, said, it, was, time, for, political, talks, with, Taiwan, and, that, the, rival, island, should, take, pra...</td>\n",
              "      <td>[O, I-LOC, O, O, O, O, I-LOC, O, O, I-LOC, O, I-LOC, O, O, O, O, O, O, O, O, O, I-LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, I-ORG, O, O, O, I-PER,...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[xxbos, German, July, car, registrations, up, 14.2, pct, yr, /, yr, ., FRANKFURT, 1996-08-22, German, first-time, registrations, of, motor, vehicles, jumped, 14.2, percent, in, July, this, year, f...</td>\n",
              "      <td>[O, I-MISC, O, O, O, O, O, O, O, O, O, O, I-LOC, O, I-MISC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                    tokens  ...    set\n",
              "0  [xxbos, EU, rejects, German, call, to, boycott, British, lamb, ., Peter, Blackburn, BRUSSELS, 1996-08-22, The, European, Commission, said, on, Thursday, it, disagreed, with, German, advice, to, co...  ...  train\n",
              "1  [xxbos, Rare, Hendrix, song, draft, sells, for, almost, $, 17,000, ., LONDON, 1996-08-22, A, rare, early, handwritten, draft, of, a, song, by, U.S., guitar, legend, Jimi, Hendrix, was, sold, for, ...  ...  train\n",
              "2  [xxbos, China, says, Taiwan, spoils, atmosphere, for, talks, ., BEIJING, 1996-08-22, China, on, Thursday, accused, Taipei, of, spoiling, the, atmosphere, for, a, resumption, of, talks, across, the...  ...  train\n",
              "3  [xxbos, China, says, time, right, for, Taiwan, talks, ., BEIJING, 1996-08-22, China, has, said, it, was, time, for, political, talks, with, Taiwan, and, that, the, rival, island, should, take, pra...  ...  train\n",
              "4  [xxbos, German, July, car, registrations, up, 14.2, pct, yr, /, yr, ., FRANKFURT, 1996-08-22, German, first-time, registrations, of, motor, vehicles, jumped, 14.2, percent, in, July, this, year, f...  ...  train\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoyGJ13eoWyu",
        "colab_type": "text"
      },
      "source": [
        "# Train LM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvO3gtN0XvLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm = (TextList.from_df(pd.concat([df, test_df], ignore_index=True), path=path, cols='tokens', processor=[num_tokens])\n",
        "           .split_by_rand_pct(0.1)\n",
        "           .label_for_lm()\n",
        "           .databunch())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKIlsjLlaWPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm.save('data_lm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8EDTXz5ac5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm = load_data(path, 'data_lm', bs=BS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcMijcTSdyJW",
        "colab_type": "code",
        "outputId": "42b7cd1f-4117-4f06-96d6-38a619c8133d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "data_lm.show_batch()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>scientific advice was xxunk . We do n't support any such recommendation because we do n't see any grounds for it , the Commission 's chief spokesman xxunk van der xxunk told a news briefing . He said further scientific study was required and if it was found that action was needed it should be taken by the European Union . He said a proposal last month by EU Farm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>by Iranian troops xxunk inside Iraq last month . A Mujahideen Khalq statement said its leader Massoud xxunk met in Baghdad the Secretary-General of the Kurdistan Democratic Party of Iran ( xxunk ) Hassan xxunk on Wednesday and voiced his support to Iran 's rebel Kurds . xxunk xxunk that the Iranian xxunk would continue to stand side by side with their Kurdish xxunk and the resistance movement in Iranian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>work and residence rights say Prime Minister Alain Juppe 's proposals are xxunk as xxunk strike enters xxunk day in Paris church and Wednesday rally xxunk 8,000 xxunk . -- xxunk xxunk nationalist movement announces end of truce after last night 's attacks . BUSINESS xxunk -- xxunk of xxunk 's French xxunk points up xxunk industry crisis , with French manufacturers xxunk by xxunk country competition and failure to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>Younis xxunk , Mohammad Akram xxunk , Mushtaq Ahmed xxunk , Aamir Sohail xxunk Pakistan : Aamir Sohail , Saeed Anwar , Ijaz Ahmed , Inzamam-ul-Haq , Salim Malik , Asif Mujtaba , Wasim Akram , Moin Khan , Mushtaq Ahmed , Waqar Younis , Mohammad Akam -DOCSTART- SOCCER - xxunk xxunk IN SCOTTISH SQUAD AFTER 20 xxunk . GLASGOW 1996-08-22 Everton 's Duncan Ferguson , who scored twice against</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>( Spain ) vs. Jordi xxunk ( Spain ) Francisco Clavet ( Spain ) vs. 16 - Cedric Pioline ( France ) ------------------------ 9 - Wayne Ferreira ( South Africa ) vs. qualifier Karol Kucera ( Slovakia ) vs. Jonas xxunk ( Sweden ) Qualifier vs. Christian xxunk ( Norway ) Alex Corretja ( Spain ) vs. Byron Black ( Zimbabwe ) David Rikl ( Czech Republic ) vs. Hicham</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KG5ZDVod7WR",
        "colab_type": "code",
        "outputId": "c40392a3-d645-439b-8b0a-3b96458380f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5,\n",
        "                               metrics=[accuracy, Perplexity()],).to_fp16(clip=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBpCoOmzfmun",
        "colab_type": "code",
        "outputId": "6aa1a477-23c3-4c35-faa6-9ed5c1a8a503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot(skip_end=15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='3' class='' max='4', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      75.00% [3/4 00:14<00:04]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>6.119419</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>6.025314</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>6.353843</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='6' class='' max='31', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      19.35% [6/31 00:00<00:03 8.6232]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEGCAYAAABPdROvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4brJLRE8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIBXozjYhAgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learn.callback_fns = [partial(EarlyStoppingCallback, monitor=\"perplexity\", mode=\"min\", patience=3),\n",
        "#                       partial(SaveModelCallback, monitor=\"perplexity\", mode=\"min\", name=\"best_model\")]\n",
        "lr = 5e-02\n",
        "moms = (0.8,0.7)\n",
        "wd = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tglyhu3dfRbA",
        "colab_type": "code",
        "outputId": "9a28f51f-604c-44b4-e80f-e63bedbe8d3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "learn.fit_one_cycle(1, slice(lr), moms=moms, wd=wd)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.930320</td>\n",
              "      <td>4.539720</td>\n",
              "      <td>0.251507</td>\n",
              "      <td>93.664528</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrDk7gAwhkd-",
        "colab_type": "code",
        "outputId": "447adee1-0169-42c2-ff44-7d89636b2c67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(5, slice(lr/5), moms=moms, wd=wd)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.820800</td>\n",
              "      <td>4.207790</td>\n",
              "      <td>0.278516</td>\n",
              "      <td>67.207840</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.566947</td>\n",
              "      <td>3.969212</td>\n",
              "      <td>0.298856</td>\n",
              "      <td>52.942799</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.222346</td>\n",
              "      <td>3.905181</td>\n",
              "      <td>0.309347</td>\n",
              "      <td>49.659054</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.875800</td>\n",
              "      <td>3.911048</td>\n",
              "      <td>0.314621</td>\n",
              "      <td>49.951279</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.614475</td>\n",
              "      <td>3.929655</td>\n",
              "      <td>0.314258</td>\n",
              "      <td>50.889385</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDBtUa3wh8D6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save_encoder('ft_enc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGI0lR5rsyIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(learn.model[0].encoder.state_dict(), path/'conll_lm-20_epochs_enc.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH0zlq4yix2C",
        "colab_type": "code",
        "outputId": "f76d4b3a-2689-4453-da04-112d5e32e3a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "learn.predict(\"A Mujahideen Khalq statement\", n_words=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"A Mujahideen Khalq statement surgery to help reduce Albion in Europe 's foreign minister\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRkNpqL3C13E",
        "colab_type": "text"
      },
      "source": [
        "# NER DataBunch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkmcLoBs8JCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2seq_collate(samples:BatchSamples, pad_idx:int=1, pad_first:bool=True, backwards:bool=False) -> Tuple[LongTensor, LongTensor]:\n",
        "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
        "    samples = to_data(samples)\n",
        "    max_len_x,max_len_y = max([len(s[0]) for s in samples]),max([len(s[1]) for s in samples])\n",
        "    res_x = torch.zeros(len(samples), max_len_x).long() + pad_idx\n",
        "    res_y = torch.zeros(len(samples), max_len_y).long() + pad_idx\n",
        "    if backwards: pad_first = not pad_first\n",
        "    for i,s in enumerate(samples):\n",
        "        if pad_first: \n",
        "            res_x[i,-len(s[0]):],res_y[i,-len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
        "        else:         \n",
        "            res_x[i,:len(s[0]):],res_y[i,:len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
        "    if backwards: res_x,res_y = res_x.flip(1),res_y.flip(1)\n",
        "    return res_x,res_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PK1uyTmVIzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2SeqDataBunch(TextDataBunch):\n",
        "    \"Create a `TextDataBunch` suitable for training an RNN classifier.\"\n",
        "    @classmethod\n",
        "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=32, val_bs:int=None, pad_idx=1,\n",
        "               dl_tfms=None, pad_first=False, device:torch.device=None, no_check:bool=False, backwards:bool=False, **dl_kwargs) -> DataBunch:\n",
        "        \"Function that transform the `datasets` in a `DataBunch` for classification. Passes `**dl_kwargs` on to `DataLoader()`\"\n",
        "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
        "        val_bs = ifnone(val_bs, bs)\n",
        "        collate_fn = partial(seq2seq_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
        "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
        "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
        "        dataloaders = [train_dl]\n",
        "        for ds in datasets[1:]:\n",
        "            lengths = [len(t) for t in ds.x.items]\n",
        "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
        "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
        "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)\n",
        "\n",
        "\n",
        "class Seq2SeqTextList(TextList):\n",
        "    _bunch = Seq2SeqDataBunch\n",
        "    _label_cls = TextList\n",
        "\n",
        "\n",
        "class NERLabelList(TextList):\n",
        "    _processor = [NumericalizeProcessor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8dvi3m8WMBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_tokens = NumericalizeProcessor()\n",
        "num_labels = NumericalizeProcessor()\n",
        "src = (Seq2SeqTextList.from_df(df, path=path, cols='tokens', processor=[num_tokens])\n",
        "       .split_by_idx(range(len(train_df), len(train_df) + len(valid_df)))\n",
        "       .label_from_df(cols='labels', label_cls=NERLabelList, processor=num_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM8hu8TsWXw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = src.databunch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3SaxCYQWfUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.save('data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xohweYXsdXJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = load_data(path, 'data', bs=BS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJKAvlIDXrn0",
        "colab_type": "code",
        "outputId": "80508fdb-61c2-4920-ef26-325b33152299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        }
      },
      "source": [
        "data.show_batch(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos ATHLETICS - BRUSSELS GRAND PRIX RESULTS . BRUSSELS 1996-08-23 Leading results in the Brussels Grand Prix athletics meeting on Friday : Women 's xxunk 1. xxunk xxunk ( Germany ) xxunk metres 2. xxunk Zvereva ( Belarus ) xxunk 3. xxunk xxunk ( Germany ) xxunk 4. Natalya xxunk ( Russia ) xxunk 5. xxunk xxunk ( Norway ) xxunk 6. xxunk xxunk ( Romania ) xxunk 7. xxunk</td>\n",
              "      <td>O O O I-MISC I-MISC I-MISC O O I-LOC O O O O O I-MISC I-MISC I-MISC O O O O O O O O O I-PER I-PER O I-LOC O O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O O O O O O I-PER I-PER O I-LOC O O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O O O O O O I-PER I-PER O I-LOC O O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O O O O O I-PER I-PER O I-LOC O O O O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O O O O O I-PER I-PER O I-LOC O O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O O O O O O I-PER I-PER O I-LOC O O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O O O O O I-PER I-PER O I-LOC O O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O O O O O I-PER I-PER O I-LOC O O O O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O O O O I-PER I-PER O I-LOC O O O O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O O O O O I-PER I-PER O I-LOC O O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O O O O O I-PER I-PER O I-LOC O O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O O O O O I-PER I-PER O I-LOC O O O O O O O O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O O O O O I-PER I-PER O I-LOC O O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O O O O O I-PER I-PER O I-LOC O O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC I-LOC O O O I-PER I-PER O I-LOC O O O O O O O I-PER I-PER O I-LOC O O O O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O O O O I-PER I-PER O I-LOC O O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O O O O O I-PER I-PER O I-LOC O O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O O O O O I-PER I-PER I-PER O I-LOC O O O O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O O O O O I-PER I-PER O I-LOC O O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O O O I-PER I-PER O I-LOC O O O O O I-PER I-PER O I-LOC O O O O O O O I-PER I-PER O I-LOC O O O O O O O O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O O I-PER I-PER O I-LOC O O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkikvUNvowTs",
        "colab_type": "text"
      },
      "source": [
        "# NER Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBZQge7D5DD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = load_data(path, 'data', bs=BS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wDxtoNTsUJg",
        "colab_type": "text"
      },
      "source": [
        "## NER LM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc8HaexPsYfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5, pretrained=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJfHydLVsYnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_rE7LKLsYi_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn06NwCvovSx",
        "colab_type": "code",
        "outputId": "720da74d-a7a6-401f-c3bb-80c5fc6f0742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "data.vocab.itos[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xxunk',\n",
              " 'xxpad',\n",
              " 'xxbos',\n",
              " 'xxeos',\n",
              " 'xxfld',\n",
              " 'xxmaj',\n",
              " 'xxup',\n",
              " 'xxrep',\n",
              " 'xxwrep',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIem8XaNqklw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pad_idx, bos_idx = 1, 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA60weVmo6_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NERRNN(nn.Module):\n",
        "    def __init__(self, emb_enc, emb_dec, nh, nout, nl=2, bos_idx=0, pad_idx=1):\n",
        "        super().__init__()\n",
        "        self.nl,self.nh, = nl,nh\n",
        "        self.bos_idx,self.pad_idx = bos_idx,pad_idx\n",
        "        self.em_sz_enc = emb_enc.embedding_dim\n",
        "        self.em_sz_dec = emb_dec.embedding_dim\n",
        "        self.nout = nout\n",
        "                 \n",
        "        self.emb_enc = emb_enc\n",
        "        self.emb_enc_drop = nn.Dropout(0.15)\n",
        "        self.gru_enc = nn.GRU(self.em_sz_enc, nh, num_layers=nl,\n",
        "                              dropout=0.25, batch_first=True)\n",
        "        self.out_enc = nn.Linear(nh, self.em_sz_dec, bias=False)\n",
        "        \n",
        "        self.emb_dec = emb_dec\n",
        "        self.gru_dec = nn.GRU(self.em_sz_dec, self.em_sz_dec, num_layers=nl,\n",
        "                              dropout=0.1, batch_first=True)\n",
        "        self.out_drop = nn.Dropout(0.35)\n",
        "        self.out = nn.Linear(self.em_sz_dec, self.nout)\n",
        "        \n",
        "    def encoder(self, bs, inp):\n",
        "        h = self.initHidden(bs)\n",
        "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
        "        _, h = self.gru_enc(emb, h)\n",
        "        h = self.out_enc(h)\n",
        "        return h\n",
        "    \n",
        "    def decoder(self, dec_inp, h):\n",
        "        emb = self.emb_dec(dec_inp).unsqueeze(1)\n",
        "        outp, h = self.gru_dec(emb, h)\n",
        "        outp = self.out(self.out_drop(outp[:,0]))\n",
        "        return h, outp\n",
        "        \n",
        "    def forward(self, inp):\n",
        "        bs, sl = inp.size()\n",
        "        h = self.encoder(bs, inp)\n",
        "        dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
        "        \n",
        "        res = []\n",
        "        for i in range(self.nout):\n",
        "            h, outp = self.decoder(dec_inp, h)\n",
        "            dec_inp = outp.max(1)[1]\n",
        "            res.append(outp)\n",
        "            if (dec_inp==self.pad_idx).all(): break\n",
        "        return torch.stack(res, dim=1)\n",
        "    \n",
        "    def initHidden(self, bs): return one_param(self).new_zeros(self.nl, bs, self.nh)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-LZK1JJqyjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb,yb = next(iter(data.valid_dl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRXtb7_RqzWN",
        "colab_type": "code",
        "outputId": "867176ab-4858-4e94-ec94-5119945783ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "xb.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1175])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRx524cf8Uaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_enc = nn.Embedding(9472, 400, padding_idx=pad_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdJDqKHat1mn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iHEt7cG8XFO",
        "colab_type": "code",
        "outputId": "f5374ab5-3d4f-46eb-8261-6df72d910940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "emb_enc.load_state_dict(torch.load(path/'conll_lm-20_epochs_enc.pth'))\n",
        "# emb_enc.load_state_dict(torch.load(path/'models/ft_enc.pth'));"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-068465d7ff7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memb_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'conll_lm-20_epochs_enc.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# emb_enc.load_state_dict(torch.load(path/'models/ft_enc.pth'));\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 839\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Embedding:\n\tsize mismatch for weight: copying a param with shape torch.Size([8136, 400]) from checkpoint, the shape in current model is torch.Size([9472, 400])."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKRR1kZfrhzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_dec = nn.Embedding(len(data.y.vocab.itos), 400, padding_idx=pad_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr9yj4GFqep-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn = NERRNN(emb_enc, emb_dec, 128, len(data.y.vocab.itos), bos_idx, pad_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0JVz2gwvqCS",
        "colab_type": "code",
        "outputId": "95c1a047-75c2-48f6-d980-b2dc9bed528a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "rnn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NERRNN(\n",
              "  (emb_enc): Embedding(9472, 400, padding_idx=1)\n",
              "  (emb_enc_drop): Dropout(p=0.15, inplace=False)\n",
              "  (gru_enc): GRU(400, 128, num_layers=2, batch_first=True, dropout=0.25)\n",
              "  (out_enc): Linear(in_features=128, out_features=400, bias=False)\n",
              "  (emb_dec): Embedding(24, 400, padding_idx=1)\n",
              "  (gru_dec): GRU(400, 400, num_layers=2, batch_first=True, dropout=0.1)\n",
              "  (out_drop): Dropout(p=0.35, inplace=False)\n",
              "  (out): Linear(in_features=400, out_features=24, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdNp3qQevqQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2seq_loss(out, targ, pad_idx=1):\n",
        "    bs,targ_len = targ.size()\n",
        "    _,out_len,vs = out.size()\n",
        "    if targ_len>out_len: out  = F.pad(out,  (0,0,0,targ_len-out_len,0,0), value=pad_idx)\n",
        "    if out_len>targ_len: targ = F.pad(targ, (0,out_len-targ_len,0,0), value=pad_idx)\n",
        "    return CrossEntropyFlat()(out, targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEIMZUoZ2T1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data, rnn, loss_func=seq2seq_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwsnZoUCr7c5",
        "colab_type": "code",
        "outputId": "075a5fcf-1ff7-4a2c-c8b3-6dfea6d783be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "learn.load_encoder(path/\"models/ft_enc.pth\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-ac874a4c3a17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"models/ft_enc.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Learner' object has no attribute 'load_encoder'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_6Uwv50DUF0",
        "colab_type": "text"
      },
      "source": [
        "# Class model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nmwP7QNFq2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm = load_data(path, 'data_lm', bs=BS)\n",
        "data_clas = load_data(path, 'data_clas', bs=BS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y0WQOt5yAVh",
        "colab_type": "code",
        "outputId": "64f10083-3b70-4fa3-e902-ab20db457dd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "# data_clas = TextClasDataBunch.from_df(path, df_train, df_valid, vocab=data_lm.train_ds.vocab, bs=BS,\n",
        "#                                       text_cols=[\"Token\"],\n",
        "#                                       label_cols=[\"Tag\"],\n",
        "#                                       include_bos=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNom0flVyZFO",
        "colab_type": "code",
        "outputId": "55df4e0f-3086-4e71-d018-385dec5a0e71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "data_clas.show_batch()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxup day -- xxup company xxrep 4 - xxup period -- xxup consensus xxrep 4 - xxup range xxrep 7 - xxup xxunk</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxup xxunk : xxmaj xxunk - xxup xxunk</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12 - 1 - 76 - 0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>four - and - a - half</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1996 - xxunk - 26</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1QI08lN5gUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_clas.save(\"data_clas\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yPyUlUeZaTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "@np_func\n",
        "def f1(inp,targ): return f1_score(targ, np.argmax(inp, axis=-1), average='weighted')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szSHi-fNVQTb",
        "colab_type": "text"
      },
      "source": [
        "## Weighted Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksjqPhT2VDxA",
        "colab_type": "code",
        "outputId": "f0e607eb-195e-40df-ce60-52206522a15e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "trn_LabelCounts = np.unique(data_clas.train_ds.y.items, return_counts=True)[1]\n",
        "val_LabelCounts = np.unique(data_clas.valid_ds.y.items, return_counts=True)[1]\n",
        "trn_LabelCounts, val_LabelCounts"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  8286,   4556,  10001,  11128, 168343]),\n",
              " array([ 2094,  1264,  2092,  3145, 42336]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cds8o-6jU87K",
        "colab_type": "code",
        "outputId": "0c0f58a2-01aa-4897-e70e-2d4882f49e5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "trn_weights = [1 - count/len(data_clas.train_ds.y) for count in trn_LabelCounts]\n",
        "val_weights = [1 - count/len(data_clas.valid_ds.y) for count in val_LabelCounts]\n",
        "trn_weights, val_weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.9590438625107506,\n",
              "  0.9774805500360825,\n",
              "  0.9505669404984332,\n",
              "  0.9449963917474816,\n",
              "  0.16791225520725206],\n",
              " [0.9588855510396419,\n",
              "  0.9751821091280359,\n",
              "  0.9589248198543127,\n",
              "  0.9382497889301211,\n",
              "  0.16875773104788827])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymCeZSlBaimx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_weights = torch.FloatTensor(trn_weights).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXZkIQ6MU0Km",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# source: https://github.com/fastai/fastai/blob/master//fastai/layers.py#L300:7\n",
        "# blog: https://bfarzin.github.io/Label-Smoothing/\n",
        "class WeightedLabelSmoothingCrossEntropy(nn.Module):\n",
        "    def __init__(self, weight, eps:float=0.1, reduction='mean'):\n",
        "        super().__init__()\n",
        "        self.weight,self.eps,self.reduction = weight,eps,reduction\n",
        "        \n",
        "    def forward(self, output, target):\n",
        "        c = output.size()[-1]\n",
        "        log_preds = F.log_softmax(output, dim=-1)\n",
        "        if self.reduction=='sum': loss = -log_preds.sum()\n",
        "        else:\n",
        "            loss = -log_preds.sum(dim=-1)\n",
        "            if self.reduction=='mean':  loss = loss.mean()\n",
        "        return loss*self.eps/c + (1-self.eps) * F.nll_loss(log_preds, target, weight=self.weight, reduction=self.reduction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR6D_BEqxWvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5, metrics=[accuracy, f1]).to_fp16(clip=0.1)\n",
        "learn.load_encoder('ft_enc');\n",
        "learn.loss_func = FlattenedLoss(WeightedLabelSmoothingCrossEntropy, weight=loss_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbF9rrCdSy2E",
        "colab_type": "code",
        "outputId": "4b6e52de-c0d5-4ae8-84c9-9e402f91ceb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "source": [
        "learn.model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(8136, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(8136, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0piqr0GxvIh",
        "colab_type": "code",
        "outputId": "e403891f-9c35-4432-f25f-bb78c042a0b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot(skip_end=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEGCAYAAAB2EqL0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxgTl/wN7SUSHNIeNMwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNRpLFwX5wLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 5e-02\n",
        "moms = (0.8,0.7)\n",
        "wd = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQIkqFHE58Zq",
        "colab_type": "code",
        "outputId": "54a962d4-3c0f-4164-edf4-38ddcdd6b314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "learn.fit_one_cycle(1, slice(lr), moms=moms, wd=wd)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.052803</td>\n",
              "      <td>0.702191</td>\n",
              "      <td>0.880073</td>\n",
              "      <td>0.871107</td>\n",
              "      <td>00:26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o-W0AggJwv_",
        "colab_type": "code",
        "outputId": "1a2424f4-c784-4fd5-f6f3-dec24f2091b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(2, slice(lr/2/(2.6**4),lr), moms=moms, wd=wd)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.012140</td>\n",
              "      <td>0.837703</td>\n",
              "      <td>0.831871</td>\n",
              "      <td>0.797422</td>\n",
              "      <td>00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.837523</td>\n",
              "      <td>0.869586</td>\n",
              "      <td>0.834462</td>\n",
              "      <td>0.802615</td>\n",
              "      <td>00:29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7A803yeJwyb",
        "colab_type": "code",
        "outputId": "414bb152-0571-48f6-af99-9efc25f4e8c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "learn.freeze_to(-3)\n",
        "learn.fit_one_cycle(2, slice(lr/2/(2.6**4),lr), moms=moms, wd=wd)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.948432</td>\n",
              "      <td>1.260719</td>\n",
              "      <td>0.843553</td>\n",
              "      <td>0.831475</td>\n",
              "      <td>00:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.852915</td>\n",
              "      <td>0.900489</td>\n",
              "      <td>0.890852</td>\n",
              "      <td>0.882369</td>\n",
              "      <td>00:34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9-hTyy8Jwru",
        "colab_type": "code",
        "outputId": "b19a975b-f257-4d1e-d577-51023d7eb68e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(2, slice(lr/5/(2.6**4),lr), moms=moms, wd=wd)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.850330</td>\n",
              "      <td>0.911130</td>\n",
              "      <td>0.889969</td>\n",
              "      <td>0.881296</td>\n",
              "      <td>00:41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.813723</td>\n",
              "      <td>0.691661</td>\n",
              "      <td>0.891736</td>\n",
              "      <td>0.883300</td>\n",
              "      <td>00:42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBNEjB9cYPT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3ednHswYOwB",
        "colab_type": "code",
        "outputId": "15ac4f01-bbef-491b-b307-21bfaec54d82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "preds,y,losses = learn.get_preds(with_loss=True)\n",
        "predictions = np.argmax(preds, axis = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sne9VnYt6CEy",
        "colab_type": "code",
        "outputId": "ef514db0-cfce-4b6d-fd97-634772cb6aaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(np.array(y), np.array(predictions))\n",
        "print(cm)\n",
        "\n",
        "## acc\n",
        "print(f'accuracy global: {(cm[0,0]+cm[1,1]+cm[2,2]+cm[3,3]+cm[4,4])/(cm.sum())}')\n",
        "\n",
        "# acc neg, acc pos\n",
        "print(f'I-LOC accuracy: {cm[0,0]/(cm.sum(1)[0])*100}') \n",
        "print(f'I-MISC accuracy: {cm[1,1]/(cm.sum(1)[1])*100}')\n",
        "print(f'I-ORG accuracy: {cm[2,2]/(cm.sum(1)[2])*100}')\n",
        "print(f'I-PER accuracy: {cm[3,3]/(cm.sum(1)[3])*100}')\n",
        "print(f'O accuracy: {cm[4,4]/(cm.sum(1)[4])*100}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  174    13   485  1403    19]\n",
            " [   19   280   134   746    85]\n",
            " [   46    18   736  1147   145]\n",
            " [    2     4   123  2941    75]\n",
            " [    6    81   245   718 41286]]\n",
            "accuracy global: 0.891735877952524\n",
            "I-LOC accuracy: 8.30945558739255\n",
            "I-MISC accuracy: 22.151898734177212\n",
            "I-ORG accuracy: 35.18164435946463\n",
            "I-PER accuracy: 93.51351351351352\n",
            "O accuracy: 97.51984126984127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34X3zymy6YB8",
        "colab_type": "code",
        "outputId": "477d4d81-9161-448f-cf5f-92f3550f38de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "learn.predict(\"United\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category I-LOC,\n",
              " tensor(0),\n",
              " tensor([ 2.3730, -1.1455,  1.0000, -4.0117, -0.1790]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcIuexMO65Wk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmqL1A5Itg5x",
        "colab_type": "text"
      },
      "source": [
        "# Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAby0IR7unwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = load_data(path, 'data', bs=BS)\n",
        "# data.show_batch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPHEv2KwZJvg",
        "colab_type": "code",
        "outputId": "da7e1e41-e3b5-4cdb-a6ad-064fe55d2600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "learn.model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(8136, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(8136, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (hidden_to_tag): Linear(in_features=1152, out_features=24, bias=True)\n",
              "    (activation): LogSoftmax()\n",
              "    (loss_f): NLLLoss()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0T2obeduKOc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ner(arch:Callable, vocab_sz:int, n_tags:int, bptt:int=70, max_len:int=20*70, config:dict=None,\n",
        "                        drop_mult:float=1., lin_ftrs:Collection[int]=None, ps:Collection[float]=None,\n",
        "                        pad_idx:int=1, weights:Collection[float]=None) -> nn.Module:\n",
        "    \"Create a text classifier from `arch` and its `config`, maybe `pretrained`.\"\n",
        "    meta = _model_meta[arch]\n",
        "    config = ifnone(config, meta['config_clas']).copy()\n",
        "    for k in config.keys():\n",
        "        if k.endswith('_p'): config[k] *= drop_mult\n",
        "    config.pop('output_p')\n",
        "    init = config.pop('init') if 'init' in config else None\n",
        "    encoder = MultiBatchEncoder(bptt, max_len, arch(vocab_sz, **config), pad_idx=pad_idx)\n",
        "    model = SequentialRNN(encoder, LinearDecoder(output_size=n_tags,\n",
        "                                                 n_hid=config[\"n_hid\"], weights=loss_weights))\n",
        "    return model if init is None else model.apply(init)\n",
        "\n",
        "def ner_learner(data:DataBunch, arch:Callable, bptt:int=70, max_len:int=70*20, config:dict=None,\n",
        "                            pretrained:bool=True, drop_mult:float=1., lin_ftrs:Collection[int]=None,\n",
        "                            ps:Collection[float]=None, weights:Collection[float]=None, **learn_kwargs) -> 'NerLearner':\n",
        "    \"Create a `Learner` with a text classifier from `data` and `arch`.\"\n",
        "    model = get_ner(arch, len(data.vocab.itos), len(data.y.vocab.itos), bptt=bptt, max_len=max_len,\n",
        "                              config=config, drop_mult=drop_mult, lin_ftrs=lin_ftrs, ps=ps,\n",
        "                              weights=weights)\n",
        "    meta = _model_meta[arch]\n",
        "    learn = RNNLearner(data, model, split_func=meta['split_clas'], **learn_kwargs)\n",
        "    if pretrained:\n",
        "        if 'url' not in meta:\n",
        "            warn(\"There are no pretrained weights for that architecture yet!\")\n",
        "            return learn\n",
        "        model_path = untar_data(meta['url'], data=False)\n",
        "        fnames = [list(model_path.glob(f'*.{ext}'))[0] for ext in ['pth', 'pkl']]\n",
        "        learn = learn.load_pretrained(*fnames, strict=False)\n",
        "        learn.freeze()\n",
        "    return learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMdPDmxKtiDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text.learner import _model_meta\n",
        "\n",
        "class LinearDecoder(nn.Module):\n",
        "    def __init__(self, output_size, n_hid, dropout_p=0.1, weights=None):\n",
        "        \"\"\"\n",
        "        :param output_size: number of tags\n",
        "        :param n_hid: encoder output dimensions\n",
        "        :param dropout: dropout to apply to *raw* encoder outputs\n",
        "        :param weights: loss weights to deal with class imbalance\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.hidden_to_tag = nn.Linear(n_hid, output_size)\n",
        "        self.activation = nn.LogSoftmax(dim=2)\n",
        "        self.loss_f = nn.NLLLoss(reduction=\"none\", weight=weights)\n",
        "        \n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Returns predictions and loss\n",
        "        \n",
        "        Parameter `mask` is used to mask out tokens such as punctuation or xxbos\n",
        "        :param input_seq: a batch of sentences of same size\n",
        "        :param output_seq: a batch of tag sequences\n",
        "        :param mask: 1 for words that you need to provide tags to\n",
        "        \"\"\"\n",
        "        input_seq, output_seq, mask = input\n",
        "\n",
        "        # encoded_states = self.dropout(self.encoder(input_seq)[0][2])\n",
        "        encoded_states = self.dropout(input_seq[0][2])\n",
        "        display(self.hidden_to_tag(encoded_states).shape)\n",
        "        predictions = self.activation(self.hidden_to_tag(encoded_states))\n",
        "        losses = list()\n",
        "        for i, (pred, active, out) in enumerate(zip(predictions, mask, output_seq)):\n",
        "            loss = self.loss_f(pred, out) * active\n",
        "            losses.append(torch.sum(loss))\n",
        "        losses = torch.stack(losses)\n",
        "        total_loss = torch.sum(losses)\n",
        "\n",
        "        return predictions, total_loss\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irL1lh_Euwfa",
        "colab_type": "code",
        "outputId": "f4a8346f-8b98-42e4-935a-c2cc9e2cf9f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "source": [
        "learn = ner_learner(data, AWD_LSTM, drop_mult=0.5, metrics=[accuracy, f1]).to_fp16()\n",
        "learn.load_encoder('ft_enc');\n",
        "# learn.loss_func = FlattenedLoss(WeightedLabelSmoothingCrossEntropy, weight=loss_weights)\n",
        "learn.lr_find()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='15', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/15 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='7', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/7 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torch.Size([1336, 24])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-dcd8b963ba8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ft_enc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# learn.loss_func = FlattenedLoss(WeightedLabelSmoothingCrossEntropy, weight=loss_weights)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/train.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(learn, start_lr, end_lr, num_it, stop_div, wd)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m def to_fp16(learn:Learner, loss_scale:float=None, max_noskip:int=1000, dynamic:bool=True, clip:float=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-99-748ee444eb80>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mencoded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_to_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_to_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAAu6nOey3Nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learn.lr_find()\n",
        "# learn.recorder.plot(skip_end=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztB6LlutzHwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "|lr = 5e-02\n",
        "moms = (0.8,0.7)\n",
        "wd = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9_51ozvasNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}